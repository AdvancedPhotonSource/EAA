# This file was autogenerated by uv via the following command:
#    uv pip compile pyproject.toml --output-file requirements.txt
annotated-types==0.7.0
    # via pydantic
anyio==4.9.0
    # via
    #   httpx
    #   openai
botorch==0.14.0
    # via eaa (pyproject.toml)
certifi==2025.4.26
    # via
    #   httpcore
    #   httpx
contourpy==1.3.2
    # via matplotlib
cycler==0.12.1
    # via matplotlib
distro==1.9.0
    # via openai
filelock==3.18.0
    # via torch
fonttools==4.57.0
    # via matplotlib
fsspec==2025.5.1
    # via torch
gpytorch==1.14
    # via botorch
h11==0.16.0
    # via httpcore
httpcore==1.0.9
    # via httpx
httpx==0.28.1
    # via openai
idna==3.10
    # via
    #   anyio
    #   httpx
imageio==2.37.0
    # via scikit-image
jaxtyping==0.3.2
    # via
    #   gpytorch
    #   linear-operator
jinja2==3.1.6
    # via torch
jiter==0.10.0
    # via openai
joblib==1.5.1
    # via scikit-learn
kiwisolver==1.4.8
    # via matplotlib
lazy-loader==0.4
    # via scikit-image
linear-operator==0.6
    # via
    #   botorch
    #   gpytorch
markupsafe==3.0.2
    # via jinja2
matplotlib==3.10.1
    # via eaa (pyproject.toml)
mpmath==1.3.0
    # via
    #   gpytorch
    #   linear-operator
    #   sympy
multipledispatch==1.0.0
    # via botorch
mypy-extensions==1.1.0
    # via typing-inspect
networkx==3.4.2
    # via
    #   scikit-image
    #   torch
numpy==2.2.5
    # via
    #   eaa (pyproject.toml)
    #   contourpy
    #   imageio
    #   matplotlib
    #   pyro-ppl
    #   scikit-image
    #   scikit-learn
    #   scipy
    #   tifffile
nvidia-cublas-cu12==12.6.4.1
    # via
    #   nvidia-cudnn-cu12
    #   nvidia-cusolver-cu12
    #   torch
nvidia-cuda-cupti-cu12==12.6.80
    # via torch
nvidia-cuda-nvrtc-cu12==12.6.77
    # via torch
nvidia-cuda-runtime-cu12==12.6.77
    # via torch
nvidia-cudnn-cu12==9.5.1.17
    # via torch
nvidia-cufft-cu12==11.3.0.4
    # via torch
nvidia-cufile-cu12==1.11.1.6
    # via torch
nvidia-curand-cu12==10.3.7.77
    # via torch
nvidia-cusolver-cu12==11.7.1.2
    # via torch
nvidia-cusparse-cu12==12.5.4.2
    # via
    #   nvidia-cusolver-cu12
    #   torch
nvidia-cusparselt-cu12==0.6.3
    # via torch
nvidia-nccl-cu12==2.26.2
    # via torch
nvidia-nvjitlink-cu12==12.6.85
    # via
    #   nvidia-cufft-cu12
    #   nvidia-cusolver-cu12
    #   nvidia-cusparse-cu12
    #   torch
nvidia-nvtx-cu12==12.6.77
    # via torch
openai==1.83.0
    # via eaa (pyproject.toml)
opt-einsum==3.4.0
    # via pyro-ppl
packaging==25.0
    # via
    #   lazy-loader
    #   matplotlib
    #   scikit-image
pillow==11.2.1
    # via
    #   imageio
    #   matplotlib
    #   scikit-image
pydantic==2.11.3
    # via openai
pydantic-core==2.33.1
    # via pydantic
pyparsing==3.2.3
    # via matplotlib
pyre-extensions==0.0.32
    # via botorch
pyro-api==0.1.2
    # via pyro-ppl
pyro-ppl==1.9.1
    # via botorch
python-dateutil==2.9.0.post0
    # via matplotlib
scikit-image==0.25.2
    # via eaa (pyproject.toml)
scikit-learn==1.6.1
    # via gpytorch
scipy==1.15.2
    # via
    #   eaa (pyproject.toml)
    #   botorch
    #   gpytorch
    #   linear-operator
    #   scikit-image
    #   scikit-learn
setuptools==80.9.0
    # via triton
six==1.17.0
    # via python-dateutil
sniffio==1.3.1
    # via
    #   anyio
    #   openai
sympy==1.14.0
    # via torch
threadpoolctl==3.6.0
    # via
    #   botorch
    #   scikit-learn
tifffile==2025.3.30
    # via scikit-image
torch==2.7.0
    # via
    #   botorch
    #   linear-operator
    #   pyro-ppl
tqdm==4.67.1
    # via
    #   eaa (pyproject.toml)
    #   openai
    #   pyro-ppl
triton==3.3.0
    # via torch
typing-extensions==4.13.2
    # via
    #   anyio
    #   botorch
    #   openai
    #   pydantic
    #   pydantic-core
    #   pyre-extensions
    #   torch
    #   typing-inspect
    #   typing-inspection
typing-inspect==0.9.0
    # via pyre-extensions
typing-inspection==0.4.0
    # via pydantic
wadler-lindig==0.1.6
    # via jaxtyping
